1.获取数据集，大小要和示例数据集差不多，如data/train/img下的杯子，而且整个数据集里的目标物体的大小也不能变化太大（128，128，3）BGR
2.标注，用labelImg标注出来xml标签参考data/train/label
3.训练：代码文件说明
	
- readxml.py 用来转换xml并生成训练所需标签，标签是一张16*16的图，其中包含物体的格子设为1，不包含的设为0
- data.py 是dataset
- train.py 是训练脚本
- test.py 测试脚本，上半部分是照片，下半部分是视频检测，检测判断是否有物体写的不太好，目前是只输出特征图中最大的那一格外加一个阈值，两者都满足了认为是一个物体，不过那个阈值是不确定的...
- model 模型文件 中间有预加载的mobilenet，预训练的是BGR通道，不过不用预训练好像也差不多，可以从model2里获取mobilenetv1的代码，截取到8*8的特征图就可以

还有一个问题是，这个检测器对物体变化大的基本没有效果，比如我要检测手掌，几百张手掌不同的造型或者抓握不同的物体做的数据集，他学不到东西。
